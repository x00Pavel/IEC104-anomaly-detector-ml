{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "from os.path import join, dirname, realpath\n",
    "import sys\n",
    "\n",
    "DATA_DIR = join(\"data\")\n",
    "\n",
    "PCAP = {\"1\": join(DATA_DIR, \"mega104-17-12-18.pcapng\"),\n",
    "        \"2\": join(DATA_DIR, \"10122018-104Mega.pcapng\"),\n",
    "        \"3\": join(DATA_DIR, \"10122018-104Mega-anomaly.pcapng\")}\n",
    "\n",
    "CSV = {\"1\": join(DATA_DIR, \"mega104-17-12-18.pcapng.csv\"),\n",
    "       \"2\": join(DATA_DIR, \"10122018-104Mega.pcapng.csv\"),\n",
    "       \"3\": join(DATA_DIR, \"10122018-104Mega-anomaly.pcapng.scv\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num=1, nu=0.0188):\n",
    "    iec104 = pd.read_csv(CSV[str(num)], header=0, skipinitialspace=True)\n",
    "\n",
    "    iec104 = iec104.drop(columns=[\"relative_time_stamp\"])\n",
    "    x_train, x_test = train_test_split(iec104, train_size=2/3, test_size=1/3,\n",
    "                                    shuffle=False, random_state=0)\n",
    "    one_class_svm = OneClassSVM(nu=nu, kernel = 'rbf', gamma = 0.1).fit(x_train)\n",
    "    dump(one_class_svm, f\"{DATA_DIR}/one-class-svm.joblib\")\n",
    "    prediction = one_class_svm.predict(x_test)\n",
    "\n",
    "    size = len(prediction)\n",
    "    t = [i for i in prediction if i == -1]\n",
    "    anomalies = len(t)\n",
    "    t = [i for i in prediction if i == 1]\n",
    "    ok = len(t)\n",
    "    perc_anom = anomalies/size\n",
    "\n",
    "    print(f\"Nu is: {nu:.4f}\")\n",
    "    print(f\"Total number of samples: {size}\")\n",
    "    print(f\"Normal: {ok} ({100*(1-perc_anom):.2f}%)\")\n",
    "    print(f\"Anomalies: {anomalies} ({100*perc_anom:.2f}%)\")\n",
    "    return [nu, perc_anom, 1 - perc_anom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nu is: 0.0188\n",
      "Total number of samples: 12554\n",
      "Normal: 12344 (98.33%)\n",
      "Anomalies: 210 (1.67%)\n",
      "Nu is: 0.0188\n",
      "Total number of samples: 22126\n",
      "Normal: 15500 (70.05%)\n",
      "Anomalies: 6626 (29.95%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0188, 0.2994666907710386, 0.7005333092289614]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(1)\n",
    "create_model(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nu is: 0.002\n",
      "Total number of samples: 12554\n",
      "Normal: 11530 (91.84%)\n",
      "Anomalies: 1024 (8.16%)\n",
      "Nu is: 0.002\n",
      "Total number of samples: 22126\n",
      "Normal: 17333 (78.34%)\n",
      "Anomalies: 4793 (21.66%)\n",
      "Nu is: 0.004\n",
      "Total number of samples: 12554\n",
      "Normal: 11970 (95.35%)\n",
      "Anomalies: 584 (4.65%)\n",
      "Nu is: 0.004\n",
      "Total number of samples: 22126\n",
      "Normal: 18579 (83.97%)\n",
      "Anomalies: 3547 (16.03%)\n",
      "Nu is: 0.006\n",
      "Total number of samples: 12554\n",
      "Normal: 11999 (95.58%)\n",
      "Anomalies: 555 (4.42%)\n",
      "Nu is: 0.006\n",
      "Total number of samples: 22126\n",
      "Normal: 20548 (92.87%)\n",
      "Anomalies: 1578 (7.13%)\n",
      "Nu is: 0.008\n",
      "Total number of samples: 12554\n",
      "Normal: 12012 (95.68%)\n",
      "Anomalies: 542 (4.32%)\n",
      "Nu is: 0.008\n",
      "Total number of samples: 22126\n",
      "Normal: 16386 (74.06%)\n",
      "Anomalies: 5740 (25.94%)\n",
      "Nu is: 0.01\n",
      "Total number of samples: 12554\n",
      "Normal: 12025 (95.79%)\n",
      "Anomalies: 529 (4.21%)\n",
      "Nu is: 0.01\n",
      "Total number of samples: 22126\n",
      "Normal: 21824 (98.64%)\n",
      "Anomalies: 302 (1.36%)\n",
      "Nu is: 0.012\n",
      "Total number of samples: 12554\n",
      "Normal: 11913 (94.89%)\n",
      "Anomalies: 641 (5.11%)\n",
      "Nu is: 0.012\n",
      "Total number of samples: 22126\n",
      "Normal: 20860 (94.28%)\n",
      "Anomalies: 1266 (5.72%)\n",
      "Nu is: 0.014\n",
      "Total number of samples: 12554\n",
      "Normal: 12231 (97.43%)\n",
      "Anomalies: 323 (2.57%)\n",
      "Nu is: 0.014\n",
      "Total number of samples: 22126\n",
      "Normal: 17517 (79.17%)\n",
      "Anomalies: 4609 (20.83%)\n",
      "Nu is: 0.016\n",
      "Total number of samples: 12554\n",
      "Normal: 12338 (98.28%)\n",
      "Anomalies: 216 (1.72%)\n",
      "Nu is: 0.016\n",
      "Total number of samples: 22126\n",
      "Normal: 16649 (75.25%)\n",
      "Anomalies: 5477 (24.75%)\n",
      "Nu is: 0.018000000000000002\n",
      "Total number of samples: 12554\n",
      "Normal: 12197 (97.16%)\n",
      "Anomalies: 357 (2.84%)\n",
      "Nu is: 0.018000000000000002\n",
      "Total number of samples: 22126\n",
      "Normal: 15991 (72.27%)\n",
      "Anomalies: 6135 (27.73%)\n",
      "Nu is: 0.020000000000000004\n",
      "Total number of samples: 12554\n",
      "Normal: 12337 (98.27%)\n",
      "Anomalies: 217 (1.73%)\n",
      "Nu is: 0.020000000000000004\n",
      "Total number of samples: 22126\n",
      "Normal: 18310 (82.75%)\n",
      "Anomalies: 3816 (17.25%)\n",
      "Nu is: 0.022000000000000006\n",
      "Total number of samples: 12554\n",
      "Normal: 12252 (97.59%)\n",
      "Anomalies: 302 (2.41%)\n",
      "Nu is: 0.022000000000000006\n",
      "Total number of samples: 22126\n",
      "Normal: 18887 (85.36%)\n",
      "Anomalies: 3239 (14.64%)\n",
      "Nu is: 0.024000000000000007\n",
      "Total number of samples: 12554\n",
      "Normal: 12252 (97.59%)\n",
      "Anomalies: 302 (2.41%)\n",
      "Nu is: 0.024000000000000007\n",
      "Total number of samples: 22126\n",
      "Normal: 15444 (69.80%)\n",
      "Anomalies: 6682 (30.20%)\n",
      "Nu is: 0.02600000000000001\n",
      "Total number of samples: 12554\n",
      "Normal: 12156 (96.83%)\n",
      "Anomalies: 398 (3.17%)\n",
      "Nu is: 0.02600000000000001\n",
      "Total number of samples: 22126\n",
      "Normal: 17288 (78.13%)\n",
      "Anomalies: 4838 (21.87%)\n",
      "Nu is: 0.02800000000000001\n",
      "Total number of samples: 12554\n",
      "Normal: 12233 (97.44%)\n",
      "Anomalies: 321 (2.56%)\n",
      "Nu is: 0.02800000000000001\n",
      "Total number of samples: 22126\n",
      "Normal: 19843 (89.68%)\n",
      "Anomalies: 2283 (10.32%)\n",
      "Nu is: 0.030000000000000013\n",
      "Total number of samples: 12554\n",
      "Normal: 12211 (97.27%)\n",
      "Anomalies: 343 (2.73%)\n",
      "Nu is: 0.030000000000000013\n",
      "Total number of samples: 22126\n",
      "Normal: 15883 (71.78%)\n",
      "Anomalies: 6243 (28.22%)\n"
     ]
    }
   ],
   "source": [
    "nu = 0.002\n",
    "result_pd_1 = []\n",
    "result_pd_2 = []\n",
    "while nu < 0.031:\n",
    "    entry = (nu, *create_model(1, nu=nu)[1:])\n",
    "    result_pd_1.append(entry)\n",
    "    entry = (nu, *create_model(2, nu=nu)[1:])\n",
    "    result_pd_2.append(entry)\n",
    "    nu += 0.002\n",
    "\n",
    "df_1 = pd.DataFrame(result_pd_1, columns=[\"nu\", \"anomalies_1\", \"ok_1\"])\n",
    "df_2 = pd.DataFrame(result_pd_2, columns=[\"nu\", \"anomalies_2\", \"ok_2\"])\n",
    "df_1.to_csv(\"./data/pandas-df.csv\")\n",
    "df_2.to_csv(\"./data/pandas-df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_sort = df_1.sort_values(by=['ok_1'], ascending=False).reset_index(drop=True)\n",
    "df_2_sort = df_2.sort_values(by=[\"ok_2\"], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016\n",
      "0.020000000000000004\n",
      "0.022000000000000006\n",
      "0.024000000000000007\n",
      "0.02800000000000001\n",
      "0.014\n",
      "0.030000000000000013\n",
      "0.018000000000000002\n",
      "0.02600000000000001\n",
      "0.01\n",
      "0.008\n",
      "0.006\n",
      "0.004\n",
      "0.012\n",
      "0.002\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(df_1_sort)):\n",
    "    e_1 = df_1_sort.iloc[i]\n",
    "    e_2 = df_2_sort.iloc[i]    \n",
    "    if e_1[\"nu\"] == e_2[\"nu\"]\n",
    "    print(e_1[\"nu\"])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d721b7aa69adfd7a06c5c74cab2c506a8d78a054b34212b5774bf472b17f188"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
