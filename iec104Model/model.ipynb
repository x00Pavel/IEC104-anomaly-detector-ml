{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "\n",
    "from os.path import join, basename, exists\n",
    "from os import makedirs, listdir, mkdir\n",
    "from shutil import rmtree\n",
    "\n",
    "import numpy as np\n",
    "import pyshark\n",
    "from traceback import print_exc\n",
    "import csv\n",
    "import concurrent.futures\n",
    "from joblib import load\n",
    "import nest_asyncio\n",
    "from itertools import product\n",
    "\n",
    "DATA_DIR = join(\"data\")\n",
    "PCAP_D = join(DATA_DIR, \"pcap\")\n",
    "CSV_D = join(DATA_DIR, \"csv\")\n",
    "MODELS_D = join(DATA_DIR, \"models\")\n",
    "INTERVALS_D = join(CSV_D, \"intervals\")\n",
    "ANOMALIES_D = join(CSV_D, \"anomalies\")\n",
    "\n",
    "for d in (DATA_DIR, PCAP_D, CSV_D, MODELS_D, INTERVALS_D, ANOMALIES_D):\n",
    "        makedirs(d, exist_ok=True)\n",
    "\n",
    "PCAP = {\"1\": join(PCAP_D, \"mega104-17-12-18.pcapng\"),\n",
    "        \"2\": join(PCAP_D, \"10122018-104Mega.pcapng\"),}\n",
    "\n",
    "CSV = {\"1\": join(CSV_D, \"mega104-17-12-18.csv\"),\n",
    "       \"2\": join(CSV_D, \"10122018-104Mega.csv\"),}\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(num=1):\n",
    "    pcap_file = PCAP[str(num)]\n",
    "    print(f\"Reading from {pcap_file}\")\n",
    "    packets = pyshark.FileCapture(pcap_file)\n",
    "\n",
    "    parsed_data = [(\"asdu_len\", \"io_type\", \"type_id\", \"src\", \"dst\", \"intervl\", \"relative_time_stamp\")]\n",
    "    \n",
    "    previous = 0\n",
    "    first_time_stamp = packets[0].sniff_time\n",
    "    relative_time = 0\n",
    "    interval = 0\n",
    "    hosts = {}\n",
    "    next_index = 0\n",
    "    for p in packets:\n",
    "        if \"iec60870_104\" not in [l.layer_name for l in p.layers]:\n",
    "            continue\n",
    "        \n",
    "        # Count time from the previous IEC 104 packet\n",
    "        if previous != 0:\n",
    "            interval = float((p.sniff_time - previous).total_seconds())\n",
    "            relative_time = (p.sniff_time - first_time_stamp).total_seconds()\n",
    "        if p.ip.src not in hosts.keys():\n",
    "            hosts[p.ip.src] = next_index\n",
    "            next_index += 1\n",
    "        if p.ip.dst not in hosts.keys():\n",
    "            hosts[p.ip.dst] = next_index\n",
    "            next_index += 1\n",
    "        \n",
    "        src = hosts[p.ip.src]\n",
    "        dst = hosts[p.ip.dst]\n",
    "        \n",
    "        previous = p.sniff_time\n",
    "        # Extract only one 'representative' for the current package\n",
    "        asdu_layer = p.get_multiple_layers(\"iec60870_asdu\")\n",
    "        if len(asdu_layer) == 0:\n",
    "            continue\n",
    "        asdu_layer = asdu_layer[0]\n",
    "\n",
    "        iec_header_layer = p.get_multiple_layers(\"iec60870_104\")\n",
    "        # Aggregate values if more then one header is present in the packet\n",
    "        iec_header = iec_header_layer[0]\n",
    "        try:\n",
    "            iec_header.apdulen = int(iec_header.apdulen)\n",
    "        except AttributeError:\n",
    "            # Not all APDU has valid apdulen attribute. Those packets in\n",
    "            # Wireshark displayed as a byte sequence, so this packet can\n",
    "            # be parsed\n",
    "            print(\"Error in converting the value in packet\")\n",
    "            print_exc()\n",
    "            print(p)\n",
    "            continue\n",
    "\n",
    "        if len(iec_header_layer) != 1:\n",
    "            for entry in iec_header_layer[1:]:\n",
    "                iec_header.apdulen += int(entry.apdulen)\n",
    "\n",
    "        try:\n",
    "            if asdu_layer:\n",
    "                parsed_data.append((iec_header.apdulen, asdu_layer.ioa, asdu_layer.typeid, src, dst, interval, relative_time))\n",
    "        except:\n",
    "            # Ignoring error if data can't be appended for some reasons.\n",
    "            print(\"Error in parsing the packet\")\n",
    "            print_exc()\n",
    "            print(p)\n",
    "\n",
    "    with open(CSV[str(num)], \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(parsed_data)\n",
    "\n",
    "    print(f\"CSV file is stored into {CSV[str(num)]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num=1, nu=0.018, kernel = 'sigmoid', gamma=\"scale\", out=True):\n",
    "    \n",
    "    out_dir = join(MODELS_D, kernel)\n",
    "    if not exists(out_dir):\n",
    "        mkdir(out_dir)\n",
    "    iec104 = pd.read_csv(CSV[str(num)], header=0, skipinitialspace=True)\n",
    "\n",
    "    iec104 = iec104.drop(columns=[\"relative_time_stamp\"])\n",
    "    x_train, x_test = train_test_split(iec104, train_size=2/3, test_size=1/3,\n",
    "                                    shuffle=False, random_state=0)\n",
    "    one_class_svm = OneClassSVM(nu=nu, kernel=kernel, gamma=gamma).fit(x_train)\n",
    "    \n",
    "    if not exists(out_dir):\n",
    "        mkdir(out_dir)\n",
    "    \n",
    "    dump(one_class_svm, join(out_dir, f\"oc-svm-{num}-nu-{nu:.3f}-{gamma}.joblib\"))\n",
    "    prediction = one_class_svm.predict(x_test)\n",
    "    size = len(prediction)\n",
    "    t = [i for i in prediction if i == -1]\n",
    "    anomalies = len(t)\n",
    "    t = [i for i in prediction if i == 1]\n",
    "    ok = len(t)\n",
    "    perc_anom = anomalies/size\n",
    "    if out:\n",
    "        print(\"-\"*(len(f\"Datset: {CSV[str(num)]}\") + 2))\n",
    "        print(f\"Datset: {CSV[str(num)]}\")\n",
    "        print(f\"Kernel: {kernel}\")\n",
    "        print(f\"Nu: {nu:.4f}\")\n",
    "        print(f\"Gamma: {gamma}\")\n",
    "        print(f\"Total number of samples: {size}\")\n",
    "        print(f\"Normal: {ok} ({100*(1-perc_anom):.2f}%)\")\n",
    "        print(f\"Anomalies: {anomalies} ({100*perc_anom:.2f}%)\")\n",
    "        print(\"-\"*(len(f\"Datset: {CSV[str(num)]}\") + 2))\n",
    "\n",
    "    return [num, kernel, nu, gamma, perc_anom, 1 - perc_anom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, nu, dataset, out=True, kernel=\"rbf\", gamma=\"scale\"):\n",
    "    model = join(MODELS_D, kernel, f\"oc-svm-{model}-nu-{nu}-{gamma}.joblib\")\n",
    "\n",
    "    svm = load(model)\n",
    "    data = pd.read_csv(dataset).drop(columns=[\"relative_time_stamp\"])\n",
    "\n",
    "    prediction = svm.predict(data)\n",
    "    size = len(prediction)\n",
    "    t = [i for i in prediction if i == -1]\n",
    "    anomalies = len(t)\n",
    "    t = [i for i in prediction if i == 1]\n",
    "    ok = len(t)\n",
    "    perc_anom = anomalies/size\n",
    "\n",
    "    if out:\n",
    "        print(\"-\"*(len(f\"Total number of samples: {size}\") + 2))\n",
    "        print(f\"Datset: {dataset}\")\n",
    "        print(f\"Total number of samples: {size}\")\n",
    "        print(f\"Normal: {ok} ({100*(1-perc_anom):.2f}%)\")\n",
    "        print(f\"Anomalies: {anomalies} ({100*perc_anom:.2f}%)\")\n",
    "        print(\"-\"*(len(f\"Total number of samples: {size}\") + 2))\n",
    "    # return prediction, (size, ok, 100*(1-perc_anom), anomalies, 100*perc_anom)\n",
    "\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interval(i, interval, model_num, type_=\"o\"):\n",
    "    f = join(INTERVALS_D, f\"model-{model_num}-{interval}min\", f\"frame-{model_num}-{i}.csv\") if type_ == \"o\" else join(ANOMALIES_D, f\"frame-{model_num}-{i}.csv\")\n",
    "    assert exists(f), f\"File {f} does not exists\"\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_anomalies(i, interval, model_num):\n",
    "    frame_name = get_interval(i, interval, model_num, type_=\"o\")\n",
    "    dst = join(ANOMALIES_D, basename(frame_name))\n",
    "    frame = pd.read_csv(frame_name)\n",
    "\n",
    "    rc = {\"frame\":dst, \"indexes\": [], \"values\": None, \"start_index\": None}\n",
    "\n",
    "    row_num = frame.shape[0]\n",
    "    # generate 15 random indexes to change size of data\n",
    "    min_size = frame[\"asdu_len\"].min()\n",
    "    max_size = frame[\"asdu_len\"].max()\n",
    "\n",
    "    if min_size < max_size:\n",
    "        rc[\"indexes\"] = np.random.randint(0, row_num, size=int(row_num*0.1))\n",
    "        rc[\"values\"] = np.random.randint(min_size, max_size, int(row_num*0.1))\n",
    "        frame.loc[rc[\"indexes\"], [\"asdu_len\"]] = rc[\"values\"]\n",
    "\n",
    "    # take range of 25 items to imitate DOS  \n",
    "    rc[\"start_index\"] = np.random.randint(0, row_num-int(row_num*0.2))\n",
    "    range_ = pd.RangeIndex(rc[\"start_index\"], rc[\"start_index\"] + int(row_num*0.2))\n",
    "\n",
    "    src = frame.loc[range_, \"src\"]\n",
    "    frame.loc[range_, \"src\"] = frame.loc[range_, \"dst\"]\n",
    "    frame.loc[range_, \"dst\"] = src\n",
    "    frame.to_csv(rc[\"frame\"], index=False)\n",
    "    \n",
    "    rc[\"indexes\"] = np.append(rc[\"indexes\"], range_)\n",
    "\n",
    "    return rc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_intervals(model_num, interval=\"5min\"):\n",
    "    interval_dir = join(INTERVALS_D, f\"model-{model_num}-{interval}\")\n",
    "    if exists(interval_dir):\n",
    "        rmtree(interval_dir)\n",
    "    \n",
    "    mkdir(interval_dir)\n",
    "\n",
    "    data = pd.read_csv(CSV[model_num])\n",
    "    data[\"relative_time_stamp\"] = pd.to_datetime(data[\"relative_time_stamp\"], unit='s',)\n",
    "    for i, frame in enumerate(data.groupby(pd.Grouper(key=\"relative_time_stamp\",freq=interval))):\n",
    "        frame[1].to_csv(join(interval_dir, f\"frame-{model_num}-{i}.csv\"), index=False, date_format=\"%M:%S.%f\")\n",
    "    return interval_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check different Nu parameter for the training of the data\n",
    "# nu = 0.002\n",
    "nus = np.arange(0.015, 0.021, 0.001)\n",
    "gammas = [\"auto\", \"scale\", 0.1]\n",
    "result = []\n",
    "\n",
    "def train(nu):\n",
    "        for g in gammas:\n",
    "                for kernel in [\"rbf\", \"sigmoid\"]:\n",
    "                        e_1 = create_model(1, nu=nu, kernel=kernel, gamma=g, out=False)[4:]\n",
    "                        e_2 = create_model(2, nu=nu, kernel=kernel, gamma=g, out=False)[4:]\n",
    "                        entry = (nu, kernel, g, *e_1, *e_2)\n",
    "                        result.append(entry)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=len(nus)) as executor:\n",
    "        executor.map(train, nus)\n",
    "\n",
    "df = pd.DataFrame(result, columns=[\"nu\", \"kernel\", \"gamma\", \"false_positive_1\", \"acc_1\", \"false_positive_2\", \"acc_2\"])\n",
    "df_sorted = df.sort_values(by=['nu'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       nu   kernel  gamma  false_positive_1     acc_1  false_positive_2  \\\n",
      "0   0.021      rbf    0.1          0.023260  0.976740          0.016632   \n",
      "1   0.021  sigmoid    0.1          1.000000  0.000000          1.000000   \n",
      "2   0.021      rbf  scale          0.018002  0.981998          0.097487   \n",
      "3   0.021  sigmoid  scale          0.021985  0.978015          0.024451   \n",
      "4   0.021      rbf   auto          0.033694  0.966306          0.365769   \n",
      "5   0.021  sigmoid   auto          1.000000  0.000000          1.000000   \n",
      "6   0.020      rbf    0.1          0.017285  0.982715          0.172467   \n",
      "7   0.020      rbf  scale          0.017684  0.982316          0.097487   \n",
      "8   0.020  sigmoid    0.1          1.000000  0.000000          1.000000   \n",
      "9   0.020  sigmoid  scale          0.020870  0.979130          0.022824   \n",
      "10  0.020      rbf   auto          0.041899  0.958101          0.313025   \n",
      "11  0.020  sigmoid   auto          1.000000  0.000000          1.000000   \n",
      "12  0.019  sigmoid   auto          1.000000  0.000000          1.000000   \n",
      "13  0.019      rbf  scale          0.016648  0.983352          0.097487   \n",
      "14  0.019  sigmoid  scale          0.020073  0.979927          0.021784   \n",
      "15  0.019      rbf    0.1          0.019914  0.980086          0.048811   \n",
      "16  0.019      rbf   auto          0.066752  0.933248          0.224758   \n",
      "17  0.019  sigmoid    0.1          1.000000  0.000000          1.000000   \n",
      "18  0.018      rbf  scale          0.016011  0.983989          0.097487   \n",
      "19  0.018  sigmoid   auto          1.000000  0.000000          1.000000   \n",
      "20  0.018      rbf   auto          0.054963  0.945037          0.100063   \n",
      "21  0.018  sigmoid  scale          0.018878  0.981122          0.020745   \n",
      "22  0.018  sigmoid    0.1          1.000000  0.000000          1.000000   \n",
      "23  0.018      rbf    0.1          0.028437  0.971563          0.277276   \n",
      "24  0.017  sigmoid    0.1          1.000000  0.000000          1.000000   \n",
      "25  0.017  sigmoid  scale          0.017604  0.982396          0.019434   \n",
      "26  0.017      rbf    0.1          0.023339  0.976661          0.018711   \n",
      "27  0.017      rbf  scale          0.014896  0.985104          0.097487   \n",
      "28  0.017  sigmoid   auto          1.000000  0.000000          1.000000   \n",
      "29  0.017      rbf   auto          0.051697  0.948303          0.227289   \n",
      "30  0.016  sigmoid    0.1          1.000000  0.000000          1.000000   \n",
      "31  0.016      rbf    0.1          0.017206  0.982794          0.247537   \n",
      "32  0.016  sigmoid  scale          0.016728  0.983272          0.018575   \n",
      "33  0.016      rbf  scale          0.014338  0.985662          0.097487   \n",
      "34  0.016  sigmoid   auto          1.000000  0.000000          1.000000   \n",
      "35  0.016      rbf   auto          0.037199  0.962801          0.074663   \n",
      "36  0.015  sigmoid    0.1          1.000000  0.000000          1.000000   \n",
      "37  0.015      rbf    0.1          0.032261  0.967739          0.476408   \n",
      "38  0.015      rbf   auto          0.052015  0.947985          0.042620   \n",
      "39  0.015  sigmoid  scale          0.015852  0.984148          0.017265   \n",
      "40  0.015      rbf  scale          0.014019  0.985981          0.097487   \n",
      "41  0.015  sigmoid   auto          1.000000  0.000000          1.000000   \n",
      "\n",
      "       acc_2  \n",
      "0   0.983368  \n",
      "1   0.000000  \n",
      "2   0.902513  \n",
      "3   0.975549  \n",
      "4   0.634231  \n",
      "5   0.000000  \n",
      "6   0.827533  \n",
      "7   0.902513  \n",
      "8   0.000000  \n",
      "9   0.977176  \n",
      "10  0.686975  \n",
      "11  0.000000  \n",
      "12  0.000000  \n",
      "13  0.902513  \n",
      "14  0.978216  \n",
      "15  0.951189  \n",
      "16  0.775242  \n",
      "17  0.000000  \n",
      "18  0.902513  \n",
      "19  0.000000  \n",
      "20  0.899937  \n",
      "21  0.979255  \n",
      "22  0.000000  \n",
      "23  0.722724  \n",
      "24  0.000000  \n",
      "25  0.980566  \n",
      "26  0.981289  \n",
      "27  0.902513  \n",
      "28  0.000000  \n",
      "29  0.772711  \n",
      "30  0.000000  \n",
      "31  0.752463  \n",
      "32  0.981425  \n",
      "33  0.902513  \n",
      "34  0.000000  \n",
      "35  0.925337  \n",
      "36  0.000000  \n",
      "37  0.523592  \n",
      "38  0.957380  \n",
      "39  0.982735  \n",
      "40  0.902513  \n",
      "41  0.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      nu   kernel  gamma  false_positive_1  false_positive_2\n",
      "0  0.015  sigmoid  scale          0.015852          0.017265\n",
      "1  0.016  sigmoid  scale          0.016728          0.018575\n",
      "2  0.017  sigmoid  scale          0.017604          0.019434\n",
      "3  0.017      rbf    0.1          0.023339          0.018711\n",
      "4  0.018  sigmoid  scale          0.018878          0.020745\n",
      "5  0.019  sigmoid  scale          0.020073          0.021784\n",
      "6  0.020  sigmoid  scale          0.020870          0.022824\n",
      "7  0.021      rbf    0.1          0.023260          0.016632\n",
      "8  0.021  sigmoid  scale          0.021985          0.024451\n"
     ]
    }
   ],
   "source": [
    "dfs = df_sorted.drop(columns=[\"acc_1\", \"acc_2\"]).loc[(df_sorted[\"false_positive_1\"] < 0.03) & (df_sorted[\"false_positive_2\"] < 0.03)].sort_values(by=['nu'], ascending=True).reset_index(drop=True)\n",
    "print(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.style.to_latex(join(CSV_D, \"summary.csv\"), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Kernel: sigmoid\n",
      "Nu: 0.0170\n",
      "Gamma: auto\n",
      "Total number of samples: 12554\n",
      "Normal: 0 (0.00%)\n",
      "Anomalies: 12554 (100.00%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Kernel: linear\n",
      "Nu: 0.0170\n",
      "Gamma: auto\n",
      "Total number of samples: 12554\n",
      "Normal: 12333 (98.24%)\n",
      "Anomalies: 221 (1.76%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Kernel: sigmoid\n",
      "Nu: 0.0170\n",
      "Gamma: 0.1\n",
      "Total number of samples: 12554\n",
      "Normal: 0 (0.00%)\n",
      "Anomalies: 12554 (100.00%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "---------------------------------------Kernel: linear\n",
      "\n",
      "Nu: 0.0170\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Kernel: linear\n",
      "Nu: 0.0170\n",
      "Gamma: 0.1\n",
      "Total number of samples: 12554\n",
      "Normal: 12333 (98.24%)\n",
      "Anomalies: 221 (1.76%)\n",
      "---------------------------------------\n",
      "Gamma: scale\n",
      "Total number of samples: 12554\n",
      "Normal: 12333 (98.24%)\n",
      "Anomalies: 221 (1.76%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Kernel: rbf\n",
      "Nu: 0.0170\n",
      "Gamma: scale\n",
      "Total number of samples: 12554\n",
      "Normal: 12367 (98.51%)\n",
      "Anomalies: 187 (1.49%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Kernel: sigmoid\n",
      "Nu: 0.0170\n",
      "Gamma: scale\n",
      "Total number of samples: 12554\n",
      "Normal: 12333 (98.24%)\n",
      "Anomalies: 221 (1.76%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Kernel: rbf\n",
      "Nu: 0.0170\n",
      "Gamma: 0.1\n",
      "Total number of samples: 12554\n",
      "Normal: 12261 (97.67%)\n",
      "Anomalies: 293 (2.33%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Kernel: rbf\n",
      "Nu: 0.0170\n",
      "Gamma: auto\n",
      "Total number of samples: 12554\n",
      "Normal: 11905 (94.83%)\n",
      "Anomalies: 649 (5.17%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Kernel: sigmoid\n",
      "Nu: 0.0170\n",
      "Gamma: auto\n",
      "Total number of samples: 22126\n",
      "Normal: 0 (0.00%)\n",
      "Anomalies: 22126 (100.00%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Kernel: linear\n",
      "Nu: 0.0170\n",
      "Gamma: auto\n",
      "Total number of samples: 22126\n",
      "Normal: 21696 (98.06%)\n",
      "Anomalies: 430 (1.94%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Kernel: linear\n",
      "Nu: 0.0170\n",
      "Gamma: scale\n",
      "Total number of samples: 22126\n",
      "Normal: 21696 (98.06%)\n",
      "Anomalies: 430 (1.94%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Kernel: linear\n",
      "Nu: 0.0170\n",
      "Gamma: 0.1\n",
      "Total number of samples: 22126\n",
      "Normal: 21696 (98.06%)\n",
      "Anomalies: 430 (1.94%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Kernel: sigmoid\n",
      "Nu: 0.0170\n",
      "Gamma: 0.1\n",
      "Total number of samples: 22126\n",
      "Normal: 0 (0.00%)---------------------------------------\n",
      "\n",
      "Anomalies: 22126 (100.00%)Datset: data/csv/10122018-104Mega.csv\n",
      "\n",
      "---------------------------------------Kernel: rbf\n",
      "\n",
      "Nu: 0.0170\n",
      "Gamma: auto\n",
      "Total number of samples: 22126\n",
      "Normal: 17097 (77.27%)\n",
      "Anomalies: 5029 (22.73%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Kernel: rbf\n",
      "Nu: 0.0170\n",
      "Gamma: scale\n",
      "Total number of samples: 22126\n",
      "Normal: 19969 (90.25%)\n",
      "Anomalies: 2157 (9.75%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Kernel: rbf\n",
      "Nu: 0.0170\n",
      "Gamma: 0.1\n",
      "Total number of samples: 22126\n",
      "Normal: 21712 (98.13%)\n",
      "Anomalies: 414 (1.87%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Kernel: sigmoid\n",
      "Nu: 0.0170\n",
      "Gamma: scale\n",
      "Total number of samples: 22126\n",
      "Normal: 21696 (98.06%)\n",
      "Anomalies: 430 (1.94%)\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "nu = 0.01\n",
    "model_nums = [\"1\", \"2\"]\n",
    "gammas = [\"auto\", \"scale\", 0.1]\n",
    "kernels = [\"linear\", \"rbf\", \"sigmoid\"]\n",
    "summary = []\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=8) as executor:\n",
    "    for r in executor.map(create_model, *zip(*product(model_nums, [nu], kernels, gammas))):\n",
    "        summary.append(r)\n",
    "summary = pd.DataFrame(summary, columns=[\"model\", \"kernel\", \"nu\", \"gamma\", \"anomalies\", \"normal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   model   kernel     nu  gamma  anomalies    normal\n",
      "0      1   linear  0.017   auto   0.017604  0.982396\n",
      "1      1   linear  0.017  scale   0.017604  0.982396\n",
      "2      1   linear  0.017    0.1   0.017604  0.982396\n",
      "3      1      rbf  0.017   auto   0.051697  0.948303\n",
      "4      1      rbf  0.017  scale   0.014896  0.985104\n",
      "5      1      rbf  0.017    0.1   0.023339  0.976661\n",
      "6      1  sigmoid  0.017   auto   1.000000  0.000000\n",
      "7      1  sigmoid  0.017  scale   0.017604  0.982396\n",
      "8      1  sigmoid  0.017    0.1   1.000000  0.000000\n",
      "9      2   linear  0.017   auto   0.019434  0.980566\n",
      "10     2   linear  0.017  scale   0.019434  0.980566\n",
      "11     2   linear  0.017    0.1   0.019434  0.980566\n",
      "12     2      rbf  0.017   auto   0.227289  0.772711\n",
      "13     2      rbf  0.017  scale   0.097487  0.902513\n",
      "14     2      rbf  0.017    0.1   0.018711  0.981289\n",
      "15     2  sigmoid  0.017   auto   1.000000  0.000000\n",
      "16     2  sigmoid  0.017  scale   0.019434  0.980566\n",
      "17     2  sigmoid  0.017    0.1   1.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_anomalies() missing 2 required positional arguments: 'interval' and 'model_num'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/iec104Model/iec104Model/model.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/iec104Model/iec104Model/model.ipynb#ch0000012?line=0'>1</a>\u001b[0m frame_num \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/iec104Model/iec104Model/model.ipynb#ch0000012?line=1'>2</a>\u001b[0m _, (ind, vals), i \u001b[39m=\u001b[39m create_anomalies(frame_num)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/iec104Model/iec104Model/model.ipynb#ch0000012?line=2'>3</a>\u001b[0m frame_anom \u001b[39m=\u001b[39m get_interval(frame_num, type_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/iec104Model/iec104Model/model.ipynb#ch0000012?line=4'>5</a>\u001b[0m res \u001b[39m=\u001b[39m predict(num, \u001b[39m0.017\u001b[39m, frame_anom)\n",
      "\u001b[0;31mTypeError\u001b[0m: create_anomalies() missing 2 required positional arguments: 'interval' and 'model_num'"
     ]
    }
   ],
   "source": [
    "frame_num = 3\n",
    "_, (ind, vals), i = create_anomalies(frame_num)\n",
    "frame_anom = get_interval(frame_num, type_='a')\n",
    "\n",
    "res = predict(num, 0.017, frame_anom)\n",
    "anoms_an = [i for i, n in enumerate(res) if n == -1]\n",
    "all_data = pd.read_csv(frame_anom)\n",
    "\n",
    "anoms_real = sorted([i for i in anoms_an if i not in anoms_ok])\n",
    "print(f\"Created {len(ind)}: {sorted(ind)}\")\n",
    "print(f\"Detected {len(anoms_real)}: {anoms_real}\")\n",
    "print(f\"{len(ind)/len(anoms_real):.02f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of original datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f0c758e0640>\n"
     ]
    }
   ],
   "source": [
    "summary = []\n",
    "nu = 0.017\n",
    "kernel = \"sigmoid\"\n",
    "for interval in [5, 7, 10]:\n",
    "    for model_num in ['1', '2']: \n",
    "        intervals_dir = split_to_intervals(model_num, f\"{interval}min\")\n",
    "\n",
    "        # Prediction\n",
    "        frames = [f for f in listdir(intervals_dir) if f\"frame-{model_num}\" in f]\n",
    "        result_acc = []\n",
    "        for f in frames:\n",
    "            fr = join(intervals_dir, f)\n",
    "    \n",
    "            # df = pd.read_csv(fr)\n",
    "            gen_labels = predict(model_num, nu, fr, out=False, kernel=kernel)\n",
    "            real_labels = np.ones(len(gen_labels), dtype=int)\n",
    "\n",
    "            result_acc.append((fr, accuracy_score(real_labels, gen_labels)))\n",
    "        \n",
    "        result_acc = pd.DataFrame(result_acc, columns=[\"dataframe\", \"accuracy\"])\n",
    "        max_acc = result_acc[(result_acc.accuracy == result_acc.accuracy.max())]\n",
    "        tmp = (model_num, kernel, interval,\n",
    "                result_acc.accuracy.min(),\n",
    "                max_acc.shape[0],\n",
    "                (max_acc.shape[0]/result_acc.shape[0])*100,\n",
    "                result_acc.accuracy.mean())\n",
    "        summary.append(tmp)\n",
    "summary = pd.DataFrame(summary, columns=[\"model number\", \"kernel\", \"interval\", \"min acc\",  \"num 100 acc\", \"% 100 acc\", \"mean acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model number   kernel  interval   min acc  num 100 acc  % 100 acc  mean acc\n",
      "0            1  sigmoid         5  0.897436          651  79.779412  0.995043\n",
      "1            2  sigmoid         5  0.988117            1   1.694915  0.994532 \n",
      "\n",
      "\n",
      "  model number   kernel  interval   min acc  num 100 acc  % 100 acc  mean acc\n",
      "2            1  sigmoid         7  0.921569          420  72.041166   0.99503\n",
      "3            2  sigmoid         7  0.991520            1   2.380952   0.99455 \n",
      "\n",
      "\n",
      "  model number   kernel  interval   min acc  num 100 acc  % 100 acc  mean acc\n",
      "4            1  sigmoid        10  0.942029          261  63.970588  0.995074\n",
      "5            2  sigmoid        10  0.989290            1   3.333333  0.994445 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_df = summary.groupby(\"interval\")\n",
    "for key, item in grouped_df:\n",
    "    # grouped_df.get_group(key).to_latex(index=False)\n",
    "    print(grouped_df.get_group(key), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job(nu, model_num, interval, kernel, gamma):\n",
    "    interval_dir = join(INTERVALS_D, f\"model-{model_num}-{interval}min\")\n",
    "    all_frames = [f for f in listdir(interval_dir) if f\"frame-{model_num}\" in f]\n",
    "    indexes = np.random.randint(0, len(all_frames), size=int(len(all_frames)*0.2))\n",
    "    summary = []\n",
    "    if type(nu) == float:\n",
    "        nu = f\"{nu:.3f}\"\n",
    "    \n",
    "    for i in indexes:\n",
    "        try:\n",
    "            result = create_anomalies(i, interval, model_num)\n",
    "        except AssertionError as e:\n",
    "            continue\n",
    "        ok_frame = get_interval(i, interval, model_num)\n",
    "\n",
    "        first_prediction = predict(model_num, nu=nu, dataset=ok_frame,\n",
    "                                    kernel=kernel, gamma=gamma, out=False)\n",
    "        prediction = predict(model_num, nu=nu, dataset=result[\"frame\"],\n",
    "                                    kernel=kernel, gamma=gamma, out=False)\n",
    "        real = np.ones(len(prediction), dtype=int)  # real labels\n",
    "        \n",
    "        anomaly_real_count = len(result[\"indexes\"])  # how much anomalies are in the interval\n",
    "        anomaly_real_perc =  (anomaly_real_count/len(first_prediction))*100\n",
    "        anomaly_detected = (1 - accuracy_score(first_prediction, prediction)) * 100\n",
    "        not_detected = anomaly_real_perc - anomaly_detected\n",
    "        false_positives = (1 - accuracy_score(real, first_prediction)) * 100\n",
    "\n",
    "        summary.append((model_num, interval, kernel, nu, gamma,\n",
    "                        anomaly_detected, anomaly_real_perc, not_detected, false_positives))\n",
    "    # print(summary)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nus = np.arange(0.005, 0.021, 0.001)\n",
    "result = []\n",
    "nus = [0.017, 0.021]\n",
    "kernels    = [\"rbf\", \"sigmoid\"]\n",
    "intervals  = [5, 7, 10]\n",
    "model_nums = [\"1\", \"2\"]\n",
    "gammas = [\"scale\", 0.1]\n",
    "\n",
    "for r in map(job, *zip(*product(nus, model_nums, intervals, kernels, gammas))):\n",
    "    result += r\n",
    "\n",
    "result = pd.DataFrame(result, columns=[\"model\", \"interval\", \"kernel\", \"nu\", \"gamma\", \"anom_detected\", \"anom_perc\", \"not_detected\", \"false_positives\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel               rbf               sigmoid           \n",
      "gamma                0.1      scale        0.1      scale\n",
      "nu    interval                                           \n",
      "0.017 5         1.398489  21.420100  21.527331   9.512613\n",
      "      7         1.473942  21.749738  23.096061  11.205972\n",
      "      10        2.039134  23.496930  24.322280  11.923516\n",
      "0.021 5         1.263915  21.281265  21.588278  11.281149\n",
      "      7         1.406228  21.574253  22.051360  11.850376\n",
      "      10        2.042682  22.643155  23.518404  13.655174\n"
     ]
    }
   ],
   "source": [
    "models_ = result.groupby([\"nu\", \"kernel\", \"interval\", \"gamma\" ])\n",
    "\n",
    "print(models_[\"not_detected\"].mean().unstack([1,3]))\n",
    "models_[\"not_detected\"].mean().unstack([1,3]).style.to_latex(join(DATA_DIR, \"not-detected-mean.tex\"), encoding=\"utf-8\")\n",
    "models_[\"false_positives\"].max().unstack([1,3]).style.to_latex(join(DATA_DIR, \"not-detected-max.tex\"), encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nu     kernel   interval  gamma\n",
      "0.017  rbf      5         0.1       1.897507\n",
      "                          scale    18.642617\n",
      "                7         0.1       2.196811\n",
      "                          scale    19.820621\n",
      "                10        0.1       1.894156\n",
      "                          scale    21.082028\n",
      "       sigmoid  5         0.1      78.277670\n",
      "                          scale     8.814422\n",
      "                7         0.1      77.109207\n",
      "                          scale     8.711453\n",
      "                10        0.1      76.709609\n",
      "                          scale    10.649333\n",
      "0.021  rbf      5         0.1       1.972456\n",
      "                          scale    18.847738\n",
      "                7         0.1       2.272380\n",
      "                          scale    19.589995\n",
      "                10        0.1       2.126934\n",
      "                          scale    19.916514\n",
      "       sigmoid  5         0.1      78.328666\n",
      "                          scale     9.037084\n",
      "                7         0.1      77.556521\n",
      "                          scale     9.800085\n",
      "                10        0.1      76.947623\n",
      "                          scale     9.830186\n",
      "Name: not_detected, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "models_ = result.groupby([\"nu\", \"kernel\", \"interval\", \"gamma\" ])\n",
    "r_ =  models_[\"not_detected\"].mean()\n",
    "print(r_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r_df = r_.to_frame().unstack([1,3])\n",
    "r_df.style.to_latex(join(DATA_DIR, \"unstack.tex\"), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nu     kernel   interval  gamma\n",
      "0.017  rbf      5         0.1       2.745209\n",
      "                          auto      7.736840\n",
      "                          scale    20.016600\n",
      "                7         0.1       2.076709\n",
      "                          auto      7.764979\n",
      "                          scale    20.208150\n",
      "                10        0.1       1.250617\n",
      "                          auto      5.795524\n",
      "                          scale    21.638794\n",
      "       sigmoid  5         0.1      76.076087\n",
      "                          auto     76.076087\n",
      "                          scale    13.314455\n",
      "                7         0.1      74.788891\n",
      "                          auto     74.788891\n",
      "                          scale    14.726779\n",
      "                10        0.1      74.201924\n",
      "                          auto     74.201924\n",
      "                          scale    15.282397\n",
      "0.021  rbf      5         0.1       3.403086\n",
      "                          auto     10.733861\n",
      "                          scale    19.648495\n",
      "                7         0.1       2.200922\n",
      "                          auto     10.588894\n",
      "                          scale    19.854972\n",
      "                10        0.1       1.498782\n",
      "                          auto      9.225785\n",
      "                          scale    21.425238\n",
      "       sigmoid  5         0.1      76.076087\n",
      "                          auto     76.076087\n",
      "                          scale    14.249463\n",
      "                7         0.1      74.788891\n",
      "                          auto     74.788891\n",
      "                          scale    15.649584\n",
      "                10        0.1      74.201924\n",
      "                          auto     74.201924\n",
      "                          scale    14.809647\n",
      "Name: not_detected, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43212/3095950487.py:4: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  r.to_latex(join(CSV_D, \"validation.tex\"), encoding='utf-8')\n"
     ]
    }
   ],
   "source": [
    "models = result.groupby([\"nu\", \"kernel\", \"interval\", \"gamma\" ])\n",
    "r =  models[\"not_detected\"].mean().unstack([1,3])\n",
    "print(r)\n",
    "r.to_latex(join(DATA_DIR, \"validation.tex\"), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_[\"not_detected\"].max().unstack([1,3]).style.to_latex(join(DATA_DIR, \"max.tex\"), encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d721b7aa69adfd7a06c5c74cab2c506a8d78a054b34212b5774bf472b17f188"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
