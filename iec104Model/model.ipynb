{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "from os.path import join, dirname, realpath\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = join(\"data\")\n",
    "\n",
    "PCAP = {\"1\": join(DATA_DIR, \"mega104-17-12-18.pcapng\"),\n",
    "        \"2\": join(DATA_DIR, \"10122018-104Mega.pcapng\"),\n",
    "        \"3\": join(DATA_DIR, \"10122018-104Mega-anomaly.pcapng\")}\n",
    "\n",
    "CSV = {\"1\": join(DATA_DIR, \"mega104-17-12-18.pcapng.csv\"),\n",
    "       \"2\": join(DATA_DIR, \"10122018-104Mega.pcapng.csv\"),\n",
    "       \"3\": join(DATA_DIR, \"10122018-104Mega-anomaly.pcapng.scv\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num=1, nu=0.0188):\n",
    "    iec104 = pd.read_csv(CSV[str(num)], header=0, skipinitialspace=True)\n",
    "\n",
    "    iec104 = iec104.drop(columns=[\"relative_time_stamp\", \"io_type\"])\n",
    "    x_train, x_test = train_test_split(iec104, train_size=2/3, test_size=1/3,\n",
    "                                    shuffle=False, random_state=0)\n",
    "    one_class_svm = OneClassSVM(nu=nu, kernel = 'rbf', gamma = 0.1).fit(x_train)\n",
    "    dump(one_class_svm, f\"{DATA_DIR}/one-class-svm-{num}.joblib\")\n",
    "    prediction = one_class_svm.predict(x_test)\n",
    "\n",
    "    size = len(prediction)\n",
    "    t = [i for i in prediction if i == -1]\n",
    "    anomalies = len(t)\n",
    "    t = [i for i in prediction if i == 1]\n",
    "    ok = len(t)\n",
    "    perc_anom = anomalies/size\n",
    "\n",
    "    print(f\"Nu is: {nu:.4f}\")\n",
    "    print(f\"Total number of samples: {size}\")\n",
    "    print(f\"Normal: {ok} ({100*(1-perc_anom):.2f}%)\")\n",
    "    print(f\"Anomalies: {anomalies} ({100*perc_anom:.2f}%)\")\n",
    "    return [nu, perc_anom, 1 - perc_anom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nu is: 0.0200\n",
      "Total number of samples: 12554\n",
      "Normal: 12294 (97.93%)\n",
      "Anomalies: 260 (2.07%)\n",
      "Nu is: 0.0200\n",
      "Total number of samples: 22126\n",
      "Normal: 17237 (77.90%)\n",
      "Anomalies: 4889 (22.10%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02, 0.2209617644400253, 0.7790382355599748]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nu = 0.02\n",
    "create_model(1, nu)\n",
    "create_model(2, nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nu is: 0.0020\n",
      "Total number of samples: 12554\n",
      "Normal: 11297 (89.99%)\n",
      "Anomalies: 1257 (10.01%)\n",
      "Nu is: 0.0020\n",
      "Total number of samples: 22126\n",
      "Normal: 16747 (75.69%)\n",
      "Anomalies: 5379 (24.31%)\n",
      "Nu is: 0.0040\n",
      "Total number of samples: 12554\n",
      "Normal: 12237 (97.47%)\n",
      "Anomalies: 317 (2.53%)\n",
      "Nu is: 0.0040\n",
      "Total number of samples: 22126\n",
      "Normal: 16215 (73.28%)\n",
      "Anomalies: 5911 (26.72%)\n",
      "Nu is: 0.0060\n",
      "Total number of samples: 12554\n",
      "Normal: 12146 (96.75%)\n",
      "Anomalies: 408 (3.25%)\n",
      "Nu is: 0.0060\n",
      "Total number of samples: 22126\n",
      "Normal: 16244 (73.42%)\n",
      "Anomalies: 5882 (26.58%)\n",
      "Nu is: 0.0080\n",
      "Total number of samples: 12554\n",
      "Normal: 12191 (97.11%)\n",
      "Anomalies: 363 (2.89%)\n",
      "Nu is: 0.0080\n",
      "Total number of samples: 22126\n",
      "Normal: 16932 (76.53%)\n",
      "Anomalies: 5194 (23.47%)\n",
      "Nu is: 0.0100\n",
      "Total number of samples: 12554\n",
      "Normal: 12402 (98.79%)\n",
      "Anomalies: 152 (1.21%)\n",
      "Nu is: 0.0100\n",
      "Total number of samples: 22126\n",
      "Normal: 20335 (91.91%)\n",
      "Anomalies: 1791 (8.09%)\n",
      "Nu is: 0.0120\n",
      "Total number of samples: 12554\n",
      "Normal: 12298 (97.96%)\n",
      "Anomalies: 256 (2.04%)\n",
      "Nu is: 0.0120\n",
      "Total number of samples: 22126\n",
      "Normal: 12605 (56.97%)\n",
      "Anomalies: 9521 (43.03%)\n",
      "Nu is: 0.0140\n",
      "Total number of samples: 12554\n",
      "Normal: 12297 (97.95%)\n",
      "Anomalies: 257 (2.05%)\n",
      "Nu is: 0.0140\n",
      "Total number of samples: 22126\n",
      "Normal: 17117 (77.36%)\n",
      "Anomalies: 5009 (22.64%)\n",
      "Nu is: 0.0160\n",
      "Total number of samples: 12554\n",
      "Normal: 12358 (98.44%)\n",
      "Anomalies: 196 (1.56%)\n",
      "Nu is: 0.0160\n",
      "Total number of samples: 22126\n",
      "Normal: 20888 (94.40%)\n",
      "Anomalies: 1238 (5.60%)\n",
      "Nu is: 0.0180\n",
      "Total number of samples: 12554\n",
      "Normal: 12315 (98.10%)\n",
      "Anomalies: 239 (1.90%)\n",
      "Nu is: 0.0180\n",
      "Total number of samples: 22126\n",
      "Normal: 13637 (61.63%)\n",
      "Anomalies: 8489 (38.37%)\n",
      "Nu is: 0.0200\n",
      "Total number of samples: 12554\n",
      "Normal: 12294 (97.93%)\n",
      "Anomalies: 260 (2.07%)\n",
      "Nu is: 0.0200\n",
      "Total number of samples: 22126\n",
      "Normal: 17237 (77.90%)\n",
      "Anomalies: 4889 (22.10%)\n",
      "Nu is: 0.0220\n",
      "Total number of samples: 12554\n",
      "Normal: 12263 (97.68%)\n",
      "Anomalies: 291 (2.32%)\n",
      "Nu is: 0.0220\n",
      "Total number of samples: 22126\n",
      "Normal: 15929 (71.99%)\n",
      "Anomalies: 6197 (28.01%)\n",
      "Nu is: 0.0240\n",
      "Total number of samples: 12554\n",
      "Normal: 12269 (97.73%)\n",
      "Anomalies: 285 (2.27%)\n",
      "Nu is: 0.0240\n",
      "Total number of samples: 22126\n",
      "Normal: 16895 (76.36%)\n",
      "Anomalies: 5231 (23.64%)\n",
      "Nu is: 0.0260\n",
      "Total number of samples: 12554\n",
      "Normal: 12228 (97.40%)\n",
      "Anomalies: 326 (2.60%)\n",
      "Nu is: 0.0260\n",
      "Total number of samples: 22126\n",
      "Normal: 20674 (93.44%)\n",
      "Anomalies: 1452 (6.56%)\n",
      "Nu is: 0.0280\n",
      "Total number of samples: 12554\n",
      "Normal: 12226 (97.39%)\n",
      "Anomalies: 328 (2.61%)\n",
      "Nu is: 0.0280\n",
      "Total number of samples: 22126\n",
      "Normal: 17046 (77.04%)\n",
      "Anomalies: 5080 (22.96%)\n",
      "Nu is: 0.0300\n",
      "Total number of samples: 12554\n",
      "Normal: 12189 (97.09%)\n",
      "Anomalies: 365 (2.91%)\n",
      "Nu is: 0.0300\n",
      "Total number of samples: 22126\n",
      "Normal: 15018 (67.87%)\n",
      "Anomalies: 7108 (32.13%)\n"
     ]
    }
   ],
   "source": [
    "nu = 0.002\n",
    "result_pd_1 = []\n",
    "result_pd_2 = []\n",
    "while nu < 0.031:\n",
    "    entry = (nu, *create_model(1, nu=nu)[1:])\n",
    "    result_pd_1.append(entry)\n",
    "    entry = (nu, *create_model(2, nu=nu)[1:])\n",
    "    result_pd_2.append(entry)\n",
    "    nu += 0.002\n",
    "\n",
    "df_1 = pd.DataFrame(result_pd_1, columns=[\"nu\", \"anomalies_1\", \"ok_1\"])\n",
    "df_2 = pd.DataFrame(result_pd_2, columns=[\"nu\", \"anomalies_2\", \"ok_2\"])\n",
    "df_1.to_csv(\"./data/pandas-df.csv\")\n",
    "df_2.to_csv(\"./data/pandas-df.csv\")\n",
    "df_1_sort = df_1.sort_values(by=['ok_1'], ascending=False).reset_index(drop=True)\n",
    "df_2_sort = df_2.sort_values(by=[\"ok_2\"], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       nu  anomalies_1      ok_1\n",
      "0   0.004     0.178987  0.821013\n",
      "1   0.020     0.188864  0.811136\n",
      "2   0.014     0.191891  0.808109\n",
      "3   0.016     0.197069  0.802931\n",
      "4   0.012     0.198582  0.801418\n",
      "5   0.026     0.200653  0.799347\n",
      "6   0.008     0.204716  0.795284\n",
      "7   0.018     0.205273  0.794727\n",
      "8   0.010     0.214035  0.785965\n",
      "9   0.022     0.217540  0.782460\n",
      "10  0.030     0.221443  0.778557\n",
      "11  0.024     0.227179  0.772821\n",
      "12  0.028     0.229648  0.770352\n",
      "13  0.002     0.239764  0.760236\n",
      "14  0.006     0.321889  0.678111\n",
      "       nu  anomalies_2      ok_2\n",
      "0   0.020     0.015231  0.984769\n",
      "1   0.006     0.021332  0.978668\n",
      "2   0.030     0.025988  0.974012\n",
      "3   0.022     0.032044  0.967956\n",
      "4   0.008     0.048585  0.951415\n",
      "5   0.012     0.081488  0.918512\n",
      "6   0.018     0.090165  0.909835\n",
      "7   0.028     0.092380  0.907620\n",
      "8   0.014     0.094911  0.905089\n",
      "9   0.002     0.105396  0.894604\n",
      "10  0.024     0.189460  0.810540\n",
      "11  0.010     0.210567  0.789433\n",
      "12  0.016     0.222046  0.777954\n",
      "13  0.004     0.295761  0.704239\n",
      "14  0.026     0.308370  0.691630\n"
     ]
    }
   ],
   "source": [
    "df_1_sort = df_1.sort_values(by=['ok_1'], ascending=False).reset_index(drop=True)\n",
    "df_2_sort = df_2.sort_values(by=[\"ok_2\"], ascending=False).reset_index(drop=True)\n",
    "print(df_1_sort)\n",
    "print(df_2_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "difs = []\n",
    "for i in range(0,len(df_1_sort)):\n",
    "    e_1 = df_1_sort.iloc[i]\n",
    "    e_2 = df_2_sort.iloc[i]\n",
    "    diff_anom = e_1['anomalies_1'] -e_2['anomalies_2']\n",
    "    difs.append(abs(e_1['anomalies_1'] - e_2['anomalies_2']))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16375583 0.16753174 0.1659035  0.16502491 0.14999675 0.11916534\n",
      " 0.11455021 0.11289321 0.1191244  0.11214386 0.031983   0.01661183\n",
      " 0.00760146 0.05599643 0.01351919]\n",
      "(array([12]),)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "difs = np.array(difs)\n",
    "\n",
    "print(difs)\n",
    "# a = difs.min(axis=1)\n",
    "a = np.where(difs == difs.min())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d721b7aa69adfd7a06c5c74cab2c506a8d78a054b34212b5774bf472b17f188"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
