{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "from os.path import join, basename\n",
    "import numpy as np\n",
    "import pyshark\n",
    "from traceback import print_exc\n",
    "import csv\n",
    "import concurrent.futures\n",
    "from joblib import load\n",
    "import nest_asyncio\n",
    "from os import makedirs\n",
    "\n",
    "DATA_DIR = join(\"data\")\n",
    "PCAP_D = join(DATA_DIR, \"pcap\")\n",
    "CSV_D = join(DATA_DIR, \"csv\")\n",
    "MODELS_D = join(DATA_DIR, \"models\")\n",
    "INTERVALS_D = join(CSV_D, \"intervals\")\n",
    "ANOMALIES_D = join(CSV_D, \"anomalies\")\n",
    "\n",
    "for d in (DATA_DIR, PCAP_D, CSV_D, MODELS_D, INTERVALS_D, ANOMALIES_D):\n",
    "        makedirs(d, exist_ok=True)\n",
    "\n",
    "PCAP = {\"1\": join(PCAP_D, \"mega104-17-12-18.pcapng\"),\n",
    "        \"2\": join(PCAP_D, \"10122018-104Mega.pcapng\"),\n",
    "        \"3\": join(PCAP_D, \"10122018-104Mega-anomaly.pcapng\")}\n",
    "\n",
    "CSV = {\"1\": join(CSV_D, \"mega104-17-12-18.csv\"),\n",
    "       \"2\": join(CSV_D, \"10122018-104Mega.csv\"),\n",
    "       \"3\": join(CSV_D, \"10122018-104Mega-anomaly.csv\")}\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(num=1):\n",
    "    pcap_file = PCAP[str(num)]\n",
    "    print(f\"Reading from {pcap_file}\")\n",
    "    packets = pyshark.FileCapture(pcap_file)\n",
    "\n",
    "    parsed_data = [(\"asdu_len\", \"io_type\", \"type_id\", \"src\", \"dst\", \"interval\", \"relative_time_stamp\")]\n",
    "    \n",
    "    previous = 0\n",
    "    first_time_stamp = packets[0].sniff_time\n",
    "    relative_time = 0\n",
    "    interval = 0\n",
    "    hosts = {}\n",
    "    next_index = 0\n",
    "    for p in packets:\n",
    "        if \"iec60870_104\" not in [l.layer_name for l in p.layers]:\n",
    "            continue\n",
    "        \n",
    "        # Count time from the previous IEC 104 packet\n",
    "        if previous != 0:\n",
    "            interval = float((p.sniff_time - previous).total_seconds())\n",
    "            relative_time = (p.sniff_time - first_time_stamp).total_seconds()\n",
    "        if p.ip.src not in hosts.keys():\n",
    "            hosts[p.ip.src] = next_index\n",
    "            next_index += 1\n",
    "        if p.ip.dst not in hosts.keys():\n",
    "            hosts[p.ip.dst] = next_index\n",
    "            next_index += 1\n",
    "        \n",
    "        src = hosts[p.ip.src]\n",
    "        dst = hosts[p.ip.dst]\n",
    "        \n",
    "        previous = p.sniff_time\n",
    "        # Extract only one 'representative' for the current package\n",
    "        asdu_layer = p.get_multiple_layers(\"iec60870_asdu\")\n",
    "        if len(asdu_layer) == 0:\n",
    "            continue\n",
    "        asdu_layer = asdu_layer[0]\n",
    "\n",
    "        iec_header_layer = p.get_multiple_layers(\"iec60870_104\")\n",
    "        # Aggregate values if more then one header is present in the packet\n",
    "        iec_header = iec_header_layer[0]\n",
    "        try:\n",
    "            iec_header.apdulen = int(iec_header.apdulen)\n",
    "        except AttributeError:\n",
    "            # Not all APDU has valid apdulen attribute. Those packets in\n",
    "            # Wireshark displayed as a byte sequence, so this packet can\n",
    "            # be parsed\n",
    "            print(\"Error in converting the value in packet\")\n",
    "            print_exc()\n",
    "            print(p)\n",
    "            continue\n",
    "\n",
    "        if len(iec_header_layer) != 1:\n",
    "            for entry in iec_header_layer[1:]:\n",
    "                iec_header.apdulen += int(entry.apdulen)\n",
    "\n",
    "        try:\n",
    "            if asdu_layer:\n",
    "                parsed_data.append((iec_header.apdulen, asdu_layer.ioa, asdu_layer.typeid, src, dst, interval, relative_time))\n",
    "        except:\n",
    "            # Ignoring error if data can't be appended for some reasons.\n",
    "            print(\"Error in parsing the packet\")\n",
    "            print_exc()\n",
    "            print(p)\n",
    "\n",
    "    with open(CSV[str(num)], \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(parsed_data)\n",
    "\n",
    "    print(f\"CSV file is stored into {CSV[str(num)]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from data/pcap/mega104-17-12-18.pcapng\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Capture.__del__ at 0x7fdc2ca0f790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py\", line 445, in __del__\n",
      "    self.close()\n",
      "  File \"/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py\", line 436, in close\n",
      "    self.eventloop.run_until_complete(self.close_async())\n",
      "  File \"/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py\", line 81, in run_until_complete\n",
      "    return f.result()\n",
      "  File \"/usr/lib/python3.8/asyncio/futures.py\", line 178, in result\n",
      "    raise self._exception\n",
      "  File \"/usr/lib/python3.8/asyncio/tasks.py\", line 280, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py\", line 440, in close_async\n",
      "    await self._cleanup_subprocess(process)\n",
      "  File \"/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py\", line 431, in _cleanup_subprocess\n",
      "    raise TSharkCrashException(\"TShark seems to have crashed (retcode: %d). \"\n",
      "pyshark.capture.capture.TSharkCrashException: TShark seems to have crashed (retcode: 2). Try rerunning in debug mode [ capture_obj.set_debug() ] or try updating tshark.\n",
      "Exception ignored in: <function Capture.__del__ at 0x7fdc2ca0f790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py\", line 445, in __del__\n",
      "    self.close()\n",
      "  File \"/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py\", line 436, in close\n",
      "    self.eventloop.run_until_complete(self.close_async())\n",
      "  File \"/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py\", line 81, in run_until_complete\n",
      "    return f.result()\n",
      "  File \"/usr/lib/python3.8/asyncio/futures.py\", line 178, in result\n",
      "    raise self._exception\n",
      "  File \"/usr/lib/python3.8/asyncio/tasks.py\", line 280, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py\", line 440, in close_async\n",
      "    await self._cleanup_subprocess(process)\n",
      "  File \"/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py\", line 431, in _cleanup_subprocess\n",
      "    raise TSharkCrashException(\"TShark seems to have crashed (retcode: %d). \"\n",
      "pyshark.capture.capture.TSharkCrashException: TShark seems to have crashed (retcode: 2). Try rerunning in debug mode [ capture_obj.set_debug() ] or try updating tshark.\n",
      "Exception ignored in: <function BaseSubprocessTransport.__del__ at 0x7fdc9c3d3ca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/base_subprocess.py\", line 126, in __del__\n",
      "    self.close()\n",
      "  File \"/usr/lib/python3.8/asyncio/base_subprocess.py\", line 104, in close\n",
      "    proto.pipe.close()\n",
      "  File \"/usr/lib/python3.8/asyncio/unix_events.py\", line 536, in close\n",
      "    self._close(None)\n",
      "  File \"/usr/lib/python3.8/asyncio/unix_events.py\", line 560, in _close\n",
      "    self._loop.call_soon(self._call_connection_lost, exc)\n",
      "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Exception ignored in: <function BaseSubprocessTransport.__del__ at 0x7fdc9c3d3ca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/base_subprocess.py\", line 126, in __del__\n",
      "    self.close()\n",
      "  File \"/usr/lib/python3.8/asyncio/base_subprocess.py\", line 104, in close\n",
      "    proto.pipe.close()\n",
      "  File \"/usr/lib/python3.8/asyncio/unix_events.py\", line 536, in close\n",
      "    self._close(None)\n",
      "  File \"/usr/lib/python3.8/asyncio/unix_events.py\", line 560, in _close\n",
      "    self._loop.call_soon(self._call_connection_lost, exc)\n",
      "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/iec104Model/iec104Model/model.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/iec104Model/iec104Model/model.ipynb#ch0000002?line=0'>1</a>\u001b[0m \u001b[39m# with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/iec104Model/iec104Model/model.ipynb#ch0000002?line=1'>2</a>\u001b[0m \u001b[39m#         executor.map(parse, [1, 2])\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/iec104Model/iec104Model/model.ipynb#ch0000002?line=2'>3</a>\u001b[0m parse(\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/iec104Model/iec104Model/model.ipynb#ch0000002?line=3'>4</a>\u001b[0m parse(\u001b[39m2\u001b[39m)\n",
      "\u001b[1;32m/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/iec104Model/iec104Model/model.ipynb Cell 2'\u001b[0m in \u001b[0;36mparse\u001b[0;34m(num)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/iec104Model/iec104Model/model.ipynb#ch0000001?line=11'>12</a>\u001b[0m hosts \u001b[39m=\u001b[39m {}\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/iec104Model/iec104Model/model.ipynb#ch0000001?line=12'>13</a>\u001b[0m next_index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/iec104Model/iec104Model/model.ipynb#ch0000001?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m packets:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/iec104Model/iec104Model/model.ipynb#ch0000001?line=14'>15</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39miec60870_104\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [l\u001b[39m.\u001b[39mlayer_name \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m p\u001b[39m.\u001b[39mlayers]:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/iec104Model/iec104Model/model.ipynb#ch0000001?line=15'>16</a>\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py:240\u001b[0m, in \u001b[0;36mCapture._packets_from_tshark_sync\u001b[0;34m(self, packet_count, existing_process)\u001b[0m\n\u001b[1;32m    <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py?line=237'>238</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py?line=238'>239</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py?line=239'>240</a>\u001b[0m         packet, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meventloop\u001b[39m.\u001b[39;49mrun_until_complete(\n\u001b[1;32m    <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py?line=240'>241</a>\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_packet_from_stream(tshark_process\u001b[39m.\u001b[39;49mstdout, data, psml_structure\u001b[39m=\u001b[39;49mpsml_structure,\n\u001b[1;32m    <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py?line=241'>242</a>\u001b[0m                                          got_first_packet\u001b[39m=\u001b[39;49mpackets_captured \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m))\n\u001b[1;32m    <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py?line=243'>244</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mEOFError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py?line=244'>245</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mEOF reached (sync)\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py:75\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py?line=72'>73</a>\u001b[0m     f\u001b[39m.\u001b[39m_log_destroy_pending \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py?line=73'>74</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m f\u001b[39m.\u001b[39mdone():\n\u001b[0;32m---> <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py?line=74'>75</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_once()\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py?line=75'>76</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stopping:\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py?line=76'>77</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py:111\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py?line=108'>109</a>\u001b[0m     handle \u001b[39m=\u001b[39m ready\u001b[39m.\u001b[39mpopleft()\n\u001b[1;32m    <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py?line=109'>110</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m handle\u001b[39m.\u001b[39m_cancelled:\n\u001b[0;32m--> <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py?line=110'>111</a>\u001b[0m         handle\u001b[39m.\u001b[39;49m_run()\n\u001b[1;32m    <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py?line=111'>112</a>\u001b[0m handle \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/asyncio/events.py:81\u001b[0m, in \u001b[0;36mHandle._run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/lib/python3.8/asyncio/events.py?line=78'>79</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     <a href='file:///usr/lib/python3.8/asyncio/events.py?line=79'>80</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///usr/lib/python3.8/asyncio/events.py?line=80'>81</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_callback, \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_args)\n\u001b[1;32m     <a href='file:///usr/lib/python3.8/asyncio/events.py?line=81'>82</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mSystemExit\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m):\n\u001b[1;32m     <a href='file:///usr/lib/python3.8/asyncio/events.py?line=82'>83</a>\u001b[0m         \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py:183\u001b[0m, in \u001b[0;36m_patch_task.<locals>.step\u001b[0;34m(task, exc)\u001b[0m\n\u001b[1;32m    <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py?line=180'>181</a>\u001b[0m curr_task \u001b[39m=\u001b[39m curr_tasks\u001b[39m.\u001b[39mget(task\u001b[39m.\u001b[39m_loop)\n\u001b[1;32m    <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py?line=181'>182</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py?line=182'>183</a>\u001b[0m     step_orig(task, exc)\n\u001b[1;32m    <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py?line=183'>184</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/nest_asyncio.py?line=184'>185</a>\u001b[0m     \u001b[39mif\u001b[39;00m curr_task \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.8/asyncio/tasks.py:280\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/asyncio/tasks.py?line=275'>276</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/asyncio/tasks.py?line=276'>277</a>\u001b[0m     \u001b[39mif\u001b[39;00m exc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/asyncio/tasks.py?line=277'>278</a>\u001b[0m         \u001b[39m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/asyncio/tasks.py?line=278'>279</a>\u001b[0m         \u001b[39m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/lib/python3.8/asyncio/tasks.py?line=279'>280</a>\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/asyncio/tasks.py?line=280'>281</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/asyncio/tasks.py?line=281'>282</a>\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m~/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py:360\u001b[0m, in \u001b[0;36mCapture._get_packet_from_stream\u001b[0;34m(self, stream, existing_data, got_first_packet, psml_structure)\u001b[0m\n\u001b[1;32m    <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py?line=357'>358</a>\u001b[0m         packet \u001b[39m=\u001b[39m packet_from_json_packet(packet, deduplicate_fields\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_json_has_duplicate_keys)\n\u001b[1;32m    <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py?line=358'>359</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py?line=359'>360</a>\u001b[0m         packet \u001b[39m=\u001b[39m packet_from_xml_packet(packet, psml_structure\u001b[39m=\u001b[39;49mpsml_structure)\n\u001b[1;32m    <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py?line=360'>361</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m packet, existing_data\n\u001b[1;32m    <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/capture/capture.py?line=362'>363</a>\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m stream\u001b[39m.\u001b[39mread(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDEFAULT_BATCH_SIZE)\n",
      "File \u001b[0;32m~/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py:34\u001b[0m, in \u001b[0;36mpacket_from_xml_packet\u001b[0;34m(xml_pkt, psml_structure)\u001b[0m\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py?line=31'>32</a>\u001b[0m \u001b[39mif\u001b[39;00m psml_structure:\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py?line=32'>33</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _packet_from_psml_packet(xml_pkt, psml_structure)\n\u001b[0;32m---> <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py?line=33'>34</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _packet_from_pdml_packet(xml_pkt)\n",
      "File \u001b[0;32m~/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py:42\u001b[0m, in \u001b[0;36m_packet_from_pdml_packet\u001b[0;34m(pdml_packet)\u001b[0m\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py?line=40'>41</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_packet_from_pdml_packet\u001b[39m(pdml_packet):\n\u001b[0;32m---> <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py?line=41'>42</a>\u001b[0m     layers \u001b[39m=\u001b[39m [Layer(proto) \u001b[39mfor\u001b[39;00m proto \u001b[39min\u001b[39;00m pdml_packet\u001b[39m.\u001b[39mproto]\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py?line=42'>43</a>\u001b[0m     geninfo, frame, layers \u001b[39m=\u001b[39m layers[\u001b[39m0\u001b[39m], layers[\u001b[39m1\u001b[39m], layers[\u001b[39m2\u001b[39m:]\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py?line=43'>44</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m Packet(layers\u001b[39m=\u001b[39mlayers, frame_info\u001b[39m=\u001b[39mframe, number\u001b[39m=\u001b[39mgeninfo\u001b[39m.\u001b[39mget_field_value(\u001b[39m'\u001b[39m\u001b[39mnum\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py?line=44'>45</a>\u001b[0m                   length\u001b[39m=\u001b[39mgeninfo\u001b[39m.\u001b[39mget_field_value(\u001b[39m'\u001b[39m\u001b[39mlen\u001b[39m\u001b[39m'\u001b[39m), sniff_time\u001b[39m=\u001b[39mgeninfo\u001b[39m.\u001b[39mget_field_value(\u001b[39m'\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m'\u001b[39m, raw\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py?line=45'>46</a>\u001b[0m                   captured_length\u001b[39m=\u001b[39mgeninfo\u001b[39m.\u001b[39mget_field_value(\u001b[39m'\u001b[39m\u001b[39mcaplen\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py?line=46'>47</a>\u001b[0m                   interface_captured\u001b[39m=\u001b[39mframe\u001b[39m.\u001b[39mget_field_value(\u001b[39m'\u001b[39m\u001b[39minterface_id\u001b[39m\u001b[39m'\u001b[39m, raw\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m~/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py:42\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py?line=40'>41</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_packet_from_pdml_packet\u001b[39m(pdml_packet):\n\u001b[0;32m---> <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py?line=41'>42</a>\u001b[0m     layers \u001b[39m=\u001b[39m [Layer(proto) \u001b[39mfor\u001b[39;00m proto \u001b[39min\u001b[39;00m pdml_packet\u001b[39m.\u001b[39mproto]\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py?line=42'>43</a>\u001b[0m     geninfo, frame, layers \u001b[39m=\u001b[39m layers[\u001b[39m0\u001b[39m], layers[\u001b[39m1\u001b[39m], layers[\u001b[39m2\u001b[39m:]\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py?line=43'>44</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m Packet(layers\u001b[39m=\u001b[39mlayers, frame_info\u001b[39m=\u001b[39mframe, number\u001b[39m=\u001b[39mgeninfo\u001b[39m.\u001b[39mget_field_value(\u001b[39m'\u001b[39m\u001b[39mnum\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py?line=44'>45</a>\u001b[0m                   length\u001b[39m=\u001b[39mgeninfo\u001b[39m.\u001b[39mget_field_value(\u001b[39m'\u001b[39m\u001b[39mlen\u001b[39m\u001b[39m'\u001b[39m), sniff_time\u001b[39m=\u001b[39mgeninfo\u001b[39m.\u001b[39mget_field_value(\u001b[39m'\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m'\u001b[39m, raw\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py?line=45'>46</a>\u001b[0m                   captured_length\u001b[39m=\u001b[39mgeninfo\u001b[39m.\u001b[39mget_field_value(\u001b[39m'\u001b[39m\u001b[39mcaplen\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/tshark/tshark_xml.py?line=46'>47</a>\u001b[0m                   interface_captured\u001b[39m=\u001b[39mframe\u001b[39m.\u001b[39mget_field_value(\u001b[39m'\u001b[39m\u001b[39minterface_id\u001b[39m\u001b[39m'\u001b[39m, raw\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m~/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/packet/layer.py:25\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, xml_obj, raw_mode)\u001b[0m\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/packet/layer.py?line=20'>21</a>\u001b[0m \u001b[39m# We copy over all the fields from the XML object\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/packet/layer.py?line=21'>22</a>\u001b[0m \u001b[39m# Note: we don't read lazily from the XML because the lxml objects are very memory-inefficient\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/packet/layer.py?line=22'>23</a>\u001b[0m \u001b[39m# so we'd rather not save them.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/packet/layer.py?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m field \u001b[39min\u001b[39;00m xml_obj\u001b[39m.\u001b[39mfindall(\u001b[39m'\u001b[39m\u001b[39m.//field\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/packet/layer.py?line=24'>25</a>\u001b[0m     attributes \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39;49m(field\u001b[39m.\u001b[39;49mattrib)\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/packet/layer.py?line=25'>26</a>\u001b[0m     field_obj \u001b[39m=\u001b[39m LayerField(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mattributes)\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/packet/layer.py?line=26'>27</a>\u001b[0m     \u001b[39mif\u001b[39;00m attributes[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m] \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_all_fields:\n\u001b[1;32m     <a href='file:///home/xyadlo00/studies/FIT/MITAI/1-rocnik/letni/PDS/proj/pds-env/lib/python3.8/site-packages/pyshark/packet/layer.py?line=27'>28</a>\u001b[0m         \u001b[39m# Field name already exists, add this field to the container.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "#         executor.map(parse, [1, 2])\n",
    "parse(1)\n",
    "parse(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, nu, dataset):\n",
    "    model = join(MODELS_D, f\"one-class-svm-{model}-nu-{nu}.joblib\")\n",
    "\n",
    "    svm = load(model)\n",
    "    data = pd.read_csv(dataset).drop(columns=[\"relative_time_stamp\"])\n",
    "\n",
    "    prediction = svm.predict(data)\n",
    "    size = len(prediction)\n",
    "    t = [i for i in prediction if i == -1]\n",
    "    anomalies = len(t)\n",
    "    t = [i for i in prediction if i == 1]\n",
    "    ok = len(t)\n",
    "    perc_anom = anomalies/size\n",
    "\n",
    "    print(\"-\"*(len(f\"Total number of samples: {size}\") + 2))\n",
    "    print(f\"Datset: {dataset}\")\n",
    "    print(f\"Total number of samples: {size}\")\n",
    "    print(f\"Normal: {ok} ({100*(1-perc_anom):.2f}%)\")\n",
    "    print(f\"Anomalies: {anomalies} ({100*perc_anom:.2f}%)\")\n",
    "    print(\"-\"*(len(f\"Total number of samples: {size}\") + 2))\n",
    "    return prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num=1, nu=0.018):\n",
    "    iec104 = pd.read_csv(CSV[str(num)], header=0, skipinitialspace=True)\n",
    "\n",
    "    iec104 = iec104.drop(columns=[\"relative_time_stamp\"])\n",
    "    x_train, x_test = train_test_split(iec104, train_size=2/3, test_size=1/3,\n",
    "                                    shuffle=False, random_state=0)\n",
    "    one_class_svm = OneClassSVM(nu=nu, kernel = 'rbf', gamma = 0.1).fit(x_train)\n",
    "    dump(one_class_svm, f\"{DATA_DIR}/models/one-class-svm-{num}-nu-{nu:.3f}.joblib\")\n",
    "    prediction = one_class_svm.predict(x_test)\n",
    "\n",
    "    size = len(prediction)\n",
    "    t = [i for i in prediction if i == -1]\n",
    "    anomalies = len(t)\n",
    "    t = [i for i in prediction if i == 1]\n",
    "    ok = len(t)\n",
    "    perc_anom = anomalies/size\n",
    "    \n",
    "    print(\"-\"*(len(f\"Datset: {CSV[str(num)]}\") + 2))\n",
    "    print(f\"Datset: {CSV[str(num)]}\")\n",
    "    print(f\"Nu is: {nu:.4f}\")\n",
    "    print(f\"Total number of samples: {size}\")\n",
    "    print(f\"Normal: {ok} ({100*(1-perc_anom):.2f}%)\")\n",
    "    print(f\"Anomalies: {anomalies} ({100*perc_anom:.2f}%)\")\n",
    "    print(\"-\"*(len(f\"Datset: {CSV[str(num)]}\") + 2))\n",
    "\n",
    "    return [nu, perc_anom, 1 - perc_anom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Nu is: 0.0170\n",
      "Total number of samples: 12554\n",
      "Normal: 12261 (97.67%)\n",
      "Anomalies: 293 (2.33%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Nu is: 0.0170\n",
      "Total number of samples: 22126\n",
      "Normal: 21712 (98.13%)\n",
      "Anomalies: 414 (1.87%)\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.017, 0.018711018711018712, 0.9812889812889813]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-shot training\n",
    "nu = 0.017\n",
    "create_model(1, nu)\n",
    "create_model(2, nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Nu is: 0.0150\n",
      "Total number of samples: 12554\n",
      "Normal: 12149 (96.77%)\n",
      "Anomalies: 405 (3.23%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Nu is: 0.0130\n",
      "Total number of samples: 12554\n",
      "Normal: 12157 (96.84%)\n",
      "Anomalies: 397 (3.16%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Nu is: 0.0140\n",
      "Total number of samples: 12554\n",
      "Normal: 12231 (97.43%)\n",
      "Anomalies: 323 (2.57%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Nu is: 0.0160\n",
      "Total number of samples: 12554\n",
      "Normal: 12338 (98.28%)\n",
      "Anomalies: 216 (1.72%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Nu is: 0.0270\n",
      "Total number of samples: 12554\n",
      "Normal: 12125 (96.58%)\n",
      "Anomalies: 429 (3.42%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Nu is: 0.0180\n",
      "Total number of samples: 12554\n",
      "Normal: 12197 (97.16%)\n",
      "Anomalies: 357 (2.84%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Nu is: 0.0170\n",
      "Total number of samples: 12554\n",
      "Normal: 12261 (97.67%)\n",
      "Anomalies: 293 (2.33%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Nu is: 0.0190\n",
      "Total number of samples: 12554\n",
      "Normal: 12304 (98.01%)\n",
      "Anomalies: 250 (1.99%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Nu is: 0.0200\n",
      "Total number of samples: 12554\n",
      "Normal: 12337 (98.27%)\n",
      "Anomalies: 217 (1.73%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Nu is: 0.0210\n",
      "Total number of samples: 12554\n",
      "Normal: 12262 (97.67%)\n",
      "Anomalies: 292 (2.33%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Nu is: 0.0220\n",
      "Total number of samples: 12554\n",
      "Normal: 12252 (97.59%)\n",
      "Anomalies: 302 (2.41%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Nu is: 0.0230\n",
      "Total number of samples: 12554\n",
      "Normal: 12219 (97.33%)\n",
      "Anomalies: 335 (2.67%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Nu is: 0.0240\n",
      "Total number of samples: 12554\n",
      "Normal: 12252 (97.59%)\n",
      "Anomalies: 302 (2.41%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Nu is: 0.0260\n",
      "Total number of samples: 12554\n",
      "Normal: 12156 (96.83%)\n",
      "Anomalies: 398 (3.17%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Nu is: 0.0150\n",
      "Total number of samples: 22126\n",
      "Normal: 11585 (52.36%)\n",
      "Anomalies: 10541 (47.64%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/mega104-17-12-18.csv\n",
      "Nu is: 0.0250\n",
      "Total number of samples: 12554\n",
      "Normal: 12219 (97.33%)\n",
      "Anomalies: 335 (2.67%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Nu is: 0.0140\n",
      "Total number of samples: 22126\n",
      "Normal: 17517 (79.17%)\n",
      "Anomalies: 4609 (20.83%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Nu is: 0.0130\n",
      "Total number of samples: 22126\n",
      "Normal: 21947 (99.19%)\n",
      "Anomalies: 179 (0.81%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Nu is: 0.0160\n",
      "Total number of samples: 22126\n",
      "Normal: 16649 (75.25%)\n",
      "Anomalies: 5477 (24.75%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Nu is: 0.0190\n",
      "Total number of samples: 22126\n",
      "Normal: 21046 (95.12%)\n",
      "Anomalies: 1080 (4.88%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Nu is: 0.0170\n",
      "Total number of samples: 22126\n",
      "Normal: 21712 (98.13%)\n",
      "Anomalies: 414 (1.87%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Nu is: 0.0220\n",
      "Total number of samples: 22126\n",
      "Normal: 18887 (85.36%)\n",
      "Anomalies: 3239 (14.64%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Nu is: 0.0180\n",
      "Total number of samples: 22126\n",
      "Normal: 15991 (72.27%)\n",
      "Anomalies: 6135 (27.73%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Nu is: 0.0270\n",
      "Total number of samples: 22126\n",
      "Normal: 14791 (66.85%)\n",
      "Anomalies: 7335 (33.15%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Nu is: 0.0200\n",
      "Total number of samples: 22126\n",
      "Normal: 18310 (82.75%)\n",
      "Anomalies: 3816 (17.25%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Nu is: 0.0210\n",
      "Total number of samples: 22126\n",
      "Normal: 21758 (98.34%)\n",
      "Anomalies: 368 (1.66%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Nu is: 0.0240\n",
      "Total number of samples: 22126\n",
      "Normal: 15444 (69.80%)\n",
      "Anomalies: 6682 (30.20%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Nu is: 0.0230\n",
      "Total number of samples: 22126\n",
      "Normal: 15911 (71.91%)\n",
      "Anomalies: 6215 (28.09%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Nu is: 0.0260\n",
      "Total number of samples: 22126\n",
      "Normal: 17288 (78.13%)\n",
      "Anomalies: 4838 (21.87%)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Datset: data/csv/10122018-104Mega.csv\n",
      "Nu is: 0.0250\n",
      "Total number of samples: 22126\n",
      "Normal: 16820 (76.02%)\n",
      "Anomalies: 5306 (23.98%)\n",
      "---------------------------------------\n",
      "      nu  anomalies_1      ok_1  anomalies_2      ok_2\n",
      "0  0.013          NaN       NaN     0.008090  0.991910\n",
      "1  0.021     0.023260  0.976740     0.016632  0.983368\n",
      "2  0.017     0.023339  0.976661     0.018711  0.981289\n"
     ]
    }
   ],
   "source": [
    "# Check different Nu parameter for the training of the data\n",
    "nu = 0.002\n",
    "result_pd_1 = []\n",
    "result_pd_2 = []\n",
    "nus = np.arange(0.013, 0.028, 0.001)\n",
    "\n",
    "def train(nu):\n",
    "    entry = (nu, *create_model(1, nu=nu)[1:])\n",
    "    result_pd_1.append(entry)\n",
    "    entry = (nu, *create_model(2, nu=nu)[1:])\n",
    "    result_pd_2.append(entry)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=len(nus)) as executor:\n",
    "        executor.map(train, nus)\n",
    "\n",
    "\n",
    "df_1 = pd.DataFrame(result_pd_1, columns=[\"nu\", \"anomalies_1\", \"ok_1\"])\n",
    "df_2 = pd.DataFrame(result_pd_2, columns=[\"nu\", \"anomalies_2\", \"ok_2\"])\n",
    "df_1.to_csv(join(CSV_D, \"pandas-df-1.csv\"))\n",
    "df_2.to_csv(join(CSV_D, \"pandas-df-2.csv\"))\n",
    "df_1_sort = df_1.sort_values(by=['ok_1'], ascending=False).reset_index(drop=True)\n",
    "df_2_sort = df_2.sort_values(by=[\"ok_2\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "ok_1 = df_1_sort.loc[(df_1_sort[\"ok_1\"] > 0.97)]\n",
    "ok_2 = df_2_sort.loc[(df_2_sort[\"ok_2\"] > 0.97)]\n",
    "\n",
    "merged = pd.merge(left=ok_1, right=ok_2, how=\"right\", left_on=\"nu\", right_on=\"nu\")\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = str(2)\n",
    "def get_interval(i, type_=\"o\"):\n",
    "    return join(INTERVALS_D, f\"frame-{num}-{i}.csv\") if type_ == \"o\" else join(ANOMALIES_D, f\"frame-{num}-{i}.csv\") \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       asdu_len  io_type  type_id  src  dst  interval  \\\n",
      "0            46       67       31    1    0  0.202736   \n",
      "1            25        2       36    1    0  3.285928   \n",
      "2            25        2       36    1    0  5.799724   \n",
      "3            25        2       36    1    0  2.992513   \n",
      "4            25        2       36    1    0  4.799476   \n",
      "...         ...      ...      ...  ...  ...       ...   \n",
      "37655        25        2       36    1    0  4.663499   \n",
      "37656        25        2       36    1    0  5.069004   \n",
      "37657        25        2       36    1    0  8.402325   \n",
      "37658        25        2       36    1    0  0.779002   \n",
      "37659        25        2       36    1    0  7.800874   \n",
      "\n",
      "             relative_time_stamp  \n",
      "0     1970-01-01 00:00:08.191193  \n",
      "1     1970-01-01 00:00:11.477121  \n",
      "2     1970-01-01 00:00:17.276845  \n",
      "3     1970-01-01 00:00:21.276420  \n",
      "4     1970-01-01 00:00:26.075896  \n",
      "...                          ...  \n",
      "37655 1970-01-03 19:54:37.419562  \n",
      "37656 1970-01-03 19:54:47.555711  \n",
      "37657 1970-01-03 19:54:55.958036  \n",
      "37658 1970-01-03 19:54:58.756241  \n",
      "37659 1970-01-03 19:55:06.557115  \n",
      "\n",
      "[37660 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(CSV[num])\n",
    "data[\"relative_time_stamp\"] = pd.to_datetime(data[\"relative_time_stamp\"], unit='s',)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to intervals for 5 minutes\n",
    "for i, frame in enumerate(data.groupby(pd.Grouper(key=\"relative_time_stamp\",freq='5min'))):\n",
    "    frame[1].to_csv(join(INTERVALS_D, f\"frame-{num}-{i}.csv\"), index=False, date_format=\"%M:%S.%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create anomalies\n",
    "def create_anomalies(i):\n",
    "    frame_name = get_interval(i, type_=\"o\")\n",
    "    frame = pd.read_csv(frame_name)\n",
    "    row_num = frame.shape[0]\n",
    "    # generate 15 random indexes to change size of data\n",
    "    min_size = frame[\"asdu_len\"].min()\n",
    "    max_size = frame[\"asdu_len\"].max()\n",
    "\n",
    "    indexes = np.random.randint(0, row_num, size=20)\n",
    "    values = np.random.randint(min_size, max_size, 20)\n",
    "\n",
    "    frame.loc[indexes, [\"asdu_len\"]] = values\n",
    "    # take range of 25 items to imitate DOS  \n",
    "    index = np.random.randint(0, row_num-10)\n",
    "    range_ = pd.RangeIndex(index, index + 10)\n",
    "    \n",
    "    src = frame.loc[range_, \"src\"]\n",
    "    frame.loc[range_, \"src\"] = frame.loc[range_, \"dst\"]\n",
    "    frame.loc[range_, \"dst\"] = src\n",
    "    frame.to_csv(join(ANOMALIES_D, basename(frame_name)), index=False)\n",
    "    indexes = np.append(indexes, range_)\n",
    "    # indexes.append()\n",
    "\n",
    "    return frame, (indexes, values), index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to intervals for 5 minutes\n",
    "for i, frame in enumerate(data.groupby(pd.Grouper(key=\"relative_time_stamp\",freq='5min'))):\n",
    "    frame[1].to_csv(join(INTERVALS_D, f\"frame-{num}-{i}.csv\"), index=False, date_format=\"%M:%S.%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (ind, vals), i = create_anomalies(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Datset: data/csv/intervals/frame-2-3.csv\n",
      "Total number of samples: 981\n",
      "Normal: 944 (96.23%)\n",
      "Anomalies: 37 (3.77%)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "frame_num = 3\n",
    "frame_ok = get_interval(frame_num, type_='o')\n",
    "\n",
    "res = predict(num, 0.017, frame_ok)\n",
    "anoms_ok = [i for i, n in enumerate(res) if n == -1]\n",
    "ok = [i for i, n in enumerate(res) if n == 1]\n",
    "all_data = pd.read_csv(frame_ok)\n",
    "\n",
    "# print(all_data.iloc[anoms])\n",
    "# print(all_data.iloc[ok])\n",
    "data_copy = all_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to intervals for 5 minutes\n",
    "for i, frame in enumerate(data.groupby(pd.Grouper(key=\"relative_time_stamp\",freq='5min'))):\n",
    "    frame[1].to_csv(join(INTERVALS_D, f\"frame-{num}-{i}.csv\"), index=False, date_format=\"%M:%S.%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Datset: data/csv/anomalies/frame-2-3.csv\n",
      "Total number of samples: 981\n",
      "Normal: 918 (93.58%)\n",
      "Anomalies: 63 (6.42%)\n",
      "------------------------------\n",
      "Created 30: [68, 119, 123, 149, 175, 302, 337, 379, 532, 587, 685, 694, 728, 729, 730, 731, 732, 733, 734, 735, 736, 736, 737, 747, 753, 775, 790, 803, 809, 869]\n",
      "Detected 26: [68, 119, 123, 149, 175, 302, 337, 379, 532, 587, 685, 694, 728, 730, 731, 732, 733, 734, 735, 736, 737, 747, 753, 775, 790, 809]\n",
      "1.15%\n"
     ]
    }
   ],
   "source": [
    "frame_num = 3\n",
    "_, (ind, vals), i = create_anomalies(frame_num)\n",
    "frame_anom = get_interval(frame_num, type_='a')\n",
    "\n",
    "res = predict(num, 0.017, frame_anom)\n",
    "anoms_an = [i for i, n in enumerate(res) if n == -1]\n",
    "all_data = pd.read_csv(frame_anom)\n",
    "\n",
    "anoms_real = sorted([i for i in anoms_an if i not in anoms_ok])\n",
    "print(f\"Created {len(ind)}: {sorted(ind)}\")\n",
    "print(f\"Detected {len(anoms_real)}: {anoms_real}\")\n",
    "print(f\"{len(ind)/len(anoms_real):.02f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[289 428 401 830 785   1 759 580 185  16]\n",
      "[321  41  62 460 413 109 425 286 110 187]\n",
      "     asdu_len  io_type  type_id  src  dst  interval relative_time_stamp\n",
      "289        17    65537      124    0    1  0.000193        26:53.578603\n",
      "428       506    65537      125    1    0  0.000808        27:35.760142\n",
      "401        17    65537      124    0    1  0.000494        27:25.386267\n",
      "830       506    65537      125    1    0  0.000001        29:26.054751\n",
      "785        17    65537      122    0    1  5.025298        29:15.614414\n",
      "1          17    65537      122    0    1  0.471748        25:03.769655\n",
      "759       506    65537      125    1    0  0.000000        29:05.098639\n",
      "580        17    65537      122    0    1  0.061247        28:17.752857\n",
      "185        57    65537      125    1    0  0.000001        26:27.417900\n",
      "16         17    65537      124    0    1  0.000517        25:04.035790\n",
      "     asdu_len  io_type  type_id  src  dst  interval relative_time_stamp  817  \\\n",
      "289       321    65537      124    0    1  0.000193        26:53.578603  478   \n",
      "428        41    65537      125    1    0  0.000808        27:35.760142  478   \n",
      "401        62    65537      124    0    1  0.000494        27:25.386267  478   \n",
      "830       460    65537      125    1    0  0.000001        29:26.054751  478   \n",
      "785       413    65537      122    0    1  5.025298        29:15.614414  478   \n",
      "1         109    65537      122    0    1  0.471748        25:03.769655  478   \n",
      "759       425    65537      125    1    0  0.000000        29:05.098639  478   \n",
      "580       286    65537      122    0    1  0.061247        28:17.752857  478   \n",
      "185       110    65537      125    1    0  0.000001        26:27.417900  478   \n",
      "16        187    65537      124    0    1  0.000517        25:04.035790  478   \n",
      "\n",
      "     177  931  ...  446  134  351  856  151  448  451  535  421  725  \n",
      "289  160  363  ...  378  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "428  160  363  ...  378  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "401  160  363  ...  378  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "830  160  363  ...  378  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "785  160  363  ...  378  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1    160  363  ...  378  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "759  160  363  ...  378  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "580  160  363  ...  378  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "185  160  363  ...  378  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "16   160  363  ...  378  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "\n",
      "[10 rows x 96 columns]\n"
     ]
    }
   ],
   "source": [
    "min_size = data_copy[\"asdu_len\"].min()\n",
    "max_size = data_copy[\"asdu_len\"].max()\n",
    "\n",
    "indexes = np.random.randint(0, data_copy.shape[0], 10)\n",
    "values = np.random.randint(min_size, max_size, 10)\n",
    "\n",
    "print(indexes)\n",
    "print(values)\n",
    "data_copy.loc[indexes, [\"asdu_len\"]] = values\n",
    "print(all_data.iloc[indexes])\n",
    "print(data_copy.iloc[indexes])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d721b7aa69adfd7a06c5c74cab2c506a8d78a054b34212b5774bf472b17f188"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
